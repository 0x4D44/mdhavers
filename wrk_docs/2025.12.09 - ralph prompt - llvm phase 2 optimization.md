# LLVM Phase 2 Optimization - List and String Performance

## Background

Phase 1 optimizations achieved Rust-parity for pure integer arithmetic (fib_iter). However, benchmarks reveal significant gaps:

| Area | Gap vs Rust | Root Cause |
|------|-------------|------------|
| Prime sieve | 10-20x slower | List access/modification overhead |
| String concat | 96x slower | Repeated allocation per concat |
| String ops | 6-8x slower | Function call overhead |
| Recursive fib | 2x slower | Parameter boxing |

## Current Architecture

### Value Representation
```rust
MdhValue = { i8 tag, i64 data }
// tag: 0=nil, 1=bool, 2=int, 3=float, 4=string, 5=list
```

### List Memory Layout
```
[length: i64][elem0: MdhValue][elem1: MdhValue]...
```
- Each element is 16 bytes (tag + data)
- `shove` uses `GC_realloc` to grow by one element each time
- Index access extracts tag+data, returns MdhValue

### String Handling
- Strings are null-terminated C strings (pointer stored in data field)
- Concatenation: `strlen(a) + strlen(b)`, `GC_malloc`, `strcpy`, `strcat`
- Creates new allocation every time

## Optimization Opportunities

### Phase 2A: List Access Optimization

**Target**: Prime sieve benchmark (currently 10-20x slower than Rust)

1. **Inline list index access**
   - Current: Calls runtime or complex branching for `arr[i]`
   - Better: Direct pointer arithmetic when list type is known
   ```llvm
   ; Current (simplified)
   %tag = extractvalue %list, 0
   %is_list = icmp eq i8 %tag, 5
   br i1 %is_list, label %access, label %error

   ; Optimized (when type known)
   %elem_ptr = getelementptr i8, ptr %list_data, i64 %offset
   %elem = load {i8, i64}, ptr %elem_ptr
   ```

2. **Inline list index assignment**
   - `arr[i] = value` should be direct store when types are known
   - Avoid runtime dispatch

3. **Track list element types**
   - If we know `arr` contains only integers, we could potentially use a more compact representation
   - For now, just skip type checks on access

### Phase 2B: List Growth Optimization

**Target**: Reduce `shove` overhead

1. **Capacity-based growth**
   - Current: Realloc every push (O(n) total for n pushes = O(n²))
   - Better: Double capacity when full (amortized O(1) per push)
   - Layout: `[capacity: i64][length: i64][elements...]`

2. **Pre-allocation hint**
   - If loop bound is known, pre-allocate capacity
   - `ken arr = []` in `whiles i < 1000` → allocate 1000 slots

### Phase 2C: String Builder Pattern

**Target**: String concatenation (currently 96x slower)

1. **Detect concatenation loops**
   - Pattern: `s = s + x` in a loop
   - Convert to StringBuilder-style buffer

2. **Inline small string concat**
   - For known-small strings, use stack buffer
   - Avoid malloc for small results

3. **String interning for literals**
   - Already done? Verify string literals aren't duplicated

### Phase 2D: Function Call Optimization

**Target**: Recursive calls (2x slower than Rust)

1. **Unboxed integer parameters**
   - When caller knows arg is int, pass raw i64
   - Generate specialized function variants: `fib_int(i64) -> i64`

2. **Tail call optimization**
   - Already marking calls as tail calls
   - Verify LLVM is actually optimizing them

3. **Inline small functions**
   - For functions < 10 instructions, inline at call site
   - Especially recursive base cases

## Implementation Plan

### Step 1: Analyze Current IR
Run benchmarks and examine LLVM IR for:
- `primes_stress.braw` - list access patterns
- `string_stress.braw` - concatenation patterns
- `fib_stress.braw` - recursive call patterns

### Step 2: Implement List Index Fast Path
In `compile_index`:
1. Check if base expression type is known to be List
2. Check if index type is known to be Int
3. If both true, generate direct GEP + load
4. Skip tag checks and error handling

### Step 3: Implement List Assignment Fast Path
In `compile_index_assign` (or wherever `arr[i] = x` is handled):
1. Similar type checking
2. Direct GEP + store

### Step 4: Benchmark and Iterate
After each change:
1. Run `primes_stress` benchmark
2. Compare with Rust
3. Examine IR for remaining inefficiencies

### Step 5: String Optimization (if time permits)
1. Identify hot string concatenation patterns
2. Implement StringBuilder for detected patterns
3. Benchmark `string_stress`

## Key Files

- `src/llvm/codegen.rs` - Main code generation
  - `compile_index` - Array indexing
  - `compile_binary` - Includes string concat
  - `inline_shove` - List push operation
  - `var_types` / `int_shadows` - Type tracking infrastructure

- `benchmarks/stress/computational/primes_stress.braw` - Primary benchmark
- `benchmarks/stress/computational/string_stress.braw` - String benchmark

## Success Criteria

1. **Primary**: Reduce prime sieve gap from 10-20x to under 5x vs Rust
2. **Secondary**: Reduce string concat gap from 96x to under 20x vs Rust
3. **Stretch**: Achieve Rust parity on recursive fibonacci

## Debugging Tips

1. Use `--emit-llvm` flag (if available) or add debug output to see generated IR
2. Compare IR before/after optimizations
3. Use `opt -O3` on generated IR to see what LLVM can optimize further
4. Profile with `perf` if needed to find hotspots
