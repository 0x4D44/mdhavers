# Comprehensive Performance Optimization for mdhavers LLVM Backend

## Current Performance Status (2025-12-10)

### Benchmark Results vs Rust

| Benchmark | mdhavers | Rust | Ratio | Priority |
|-----------|----------|------|-------|----------|
| **Fibonacci iterative** | 2 μs | 4 μs | **0.5x faster** | ✅ |
| **Fibonacci recursive (30)** | 2 ms | 1 ms | 2x slower | LOW |
| **String concat 1000** | 2 μs | 2 μs | **1x (equal)** | ✅ |
| **String upper 1000x** | 161 μs | 9 μs | **18x slower** | CRITICAL |
| **String lower 1000x** | 41 μs | 10 μs | 4x slower | HIGH |
| **String split 1000x** | 608 μs | 77 μs | **8x slower** | HIGH |
| **String join 1000x** | 77 μs | 15 μs | **5x slower** | HIGH |
| **Primes sieve(1000)** | 13 μs | 3 μs | **4x slower** | HIGH |
| **Primes sieve(5000)** | 70 μs | 10 μs | **7x slower** | HIGH |
| **Primes sieve(10000)** | 101 μs | 20 μs | **5x slower** | HIGH |
| **Primes sieve(20000)** | 197 μs | 38 μs | **5x slower** | HIGH |
| **List build 10K** | 99 μs | N/A | - | MEDIUM |
| **List slice 1000x** | 437 μs | N/A | - | MEDIUM |

## Priority 1: String upper() - 18x Slower (CRITICAL)

### Analysis
The `upper()` function shows 161 μs vs Rust's 9 μs - a massive 18x gap. Strangely, `lower()` at 41 μs is only 4x slower. Both have inline ASCII math implemented but something is causing upper() to be extremely slow.

### Investigation Steps
1. Check if `upper()` is actually using the inline ASCII path or falling back to libc toupper
2. Compare the LLVM IR generated for upper vs lower
3. Look for extra allocations or strlen calls in upper that aren't in lower
4. Check if there's a branch misprediction issue with the comparison order

### Potential Issues
- Buffer allocation: Both upper() and lower() allocate new buffers via malloc
- strlen call: Both call strlen to get source length
- Loop structure differences: Check if loops are structured identically

### Optimization Strategies
1. Use string length shadow if the argument is a known variable
2. Reuse buffer when possible (in-place transformation for local variables)
3. Process 8 bytes at a time using SIMD-like operations (4x or 8x unrolling)
4. Check if malloc call overhead is significant

## Priority 2: String split() - 8x Slower

### Analysis
`split()` at 608 μs vs Rust's 77 μs (8x gap). The current implementation:
- Uses strstr for each delimiter search
- Allocates list with malloc
- Creates new string allocations for each token
- Fixed initial capacity of 100 elements

### Optimization Strategies
1. **Inline delimiter matching**: For single-char delimiters, avoid strstr overhead
2. **Single-pass scanning**: Count delimiters first, then allocate exact size
3. **String interning**: For small strings, use stack allocation
4. **Avoid strlen per token**: Track positions with indices instead

### Implementation
```
// For single-char delimiter (common case like ",")
if delimiter_len == 1:
    // Use byte comparison instead of strstr
    for i in 0..str_len:
        if str[i] == delim_byte:
            emit_token()
```

## Priority 3: String join() - 5x Slower

### Analysis
`join()` at 77 μs vs Rust's 15 μs (5x gap).

### Optimization Strategies
1. **Pre-calculate total length**: Sum all element lengths + (count-1) * delimiter_length
2. **Single allocation**: malloc once with exact size
3. **Use memcpy for each segment**: Avoid strcat overhead
4. **Track write position**: Use index arithmetic instead of pointer arithmetic

## Priority 4: Primes Sieve - 5-7x Slower

### Analysis
The sieve benchmark tests list operations heavily:
- Building boolean array with `shove(is_prime, aye)` - 20K+ pushes
- Array index access `is_prime[p]` and `is_prime[j]`
- Array assignment `is_prime[j] = nae`
- Building result list with `shove(primes, k)`

### Root Causes
1. **List growth**: Each `shove` may trigger reallocation
2. **MdhValue boxing**: Booleans stored as tagged 16-byte values
3. **Index access**: May involve bounds checking and tag extraction
4. **Type tagging overhead**: Every boolean read/write involves tag manipulation

### Optimization Strategies

#### A. Specialize Boolean Arrays
Detect boolean array patterns and use packed bit arrays:
```rust
// Instead of MdhValue[] with 16 bytes per boolean
// Use u8[] with 8 booleans per byte
```

#### B. Fast List Growth
Pre-allocate with exponential growth:
```rust
// Current: may allocate exact size each time
// Better: capacity = max(16, old_capacity * 2)
```

#### C. Unboxed Local Arrays
For local variables that are arrays with known element types:
```rust
// If all elements are Int, use i64[]
// If all elements are Bool, use i8[] or bitset
```

#### D. List Index Optimization
- Remove bounds checks in tight loops where index is provably valid
- Cache list pointer and length at loop start
- Use direct pointer arithmetic instead of repeated struct access

## Priority 5: Lower() Still 4x Slower

### Analysis
Even with inline ASCII math, lower() at 41 μs vs 10 μs shows 4x gap.

### Optimization Strategies
1. **SIMD processing**: Process 8 chars at a time with vectorized operations
2. **Inline the entire loop in LLVM**: Ensure no function call overhead
3. **Use LLVM intrinsics**: llvm.ctlz, llvm.bswap for parallel processing

## Priority 6: List Operations

### Build 10K List (99 μs)
- Pre-allocate with known size when building from range
- Avoid per-element tagging if homogeneous

### Slice 1000x (437 μs)
- Single memcpy for element block instead of per-element copy
- Share underlying storage with copy-on-write semantics

## Implementation Order

### Phase 1: Investigate upper() anomaly (FIRST)
1. Generate LLVM IR for upper() and lower()
2. Compare instruction counts
3. Fix any obvious issues

### Phase 2: Single-char delimiter fast path for split()
1. Check delimiter length at compile time if literal
2. Use byte scan for single-char case

### Phase 3: Pre-calculate join() length
1. Two-pass: count + allocate
2. Single allocation with exact size

### Phase 4: List operation optimizations
1. Add exponential growth to shove()
2. Cache list length/pointer at loop start
3. Specialize boolean arrays for sieve patterns

### Phase 5: SIMD-style string ops
1. Process multiple bytes per iteration
2. Use LLVM vector operations

## Testing

After each optimization:
```bash
./target/release/mdhavers build benchmarks/stress/computational/string_stress.braw -o /tmp/string_stress && /tmp/string_stress
./target/release/mdhavers build benchmarks/stress/computational/primes_stress.braw -o /tmp/primes_stress && /tmp/primes_stress
./target/release/mdhavers build benchmarks/stress/memory/list_stress.braw -o /tmp/list_stress && /tmp/list_stress
```

## Target Goals

| Operation | Current | Target | Goal vs Rust |
|-----------|---------|--------|--------------|
| upper() | 161 μs | 20 μs | 2x slower max |
| lower() | 41 μs | 15 μs | 1.5x slower max |
| split() | 608 μs | 150 μs | 2x slower max |
| join() | 77 μs | 30 μs | 2x slower max |
| sieve(20K) | 197 μs | 80 μs | 2x slower max |

## Files to Modify

- `src/llvm/codegen.rs` - Main LLVM codegen (inline_upper, inline_lower, inline_split, inline_join, inline_shove)
- `src/llvm/mod.rs` - May need new types or helpers

## Key Code Locations

- `inline_upper()` - Line ~4060
- `inline_lower()` - Line ~4182
- `inline_split()` - Line ~8397
- `inline_join()` - Search for "join" function
- `inline_shove()` - Line ~2981
- `compile_while()` - Line ~6584 (for loop optimizations)
- `compile_index()` - List indexing (search for Index pattern)

## Completion Criteria

The optimization work is complete when:
1. String upper() is under 30 μs (from 161 μs)
2. String split() is under 200 μs (from 608 μs)
3. Primes sieve(20K) is under 100 μs (from 197 μs)

Primary target: **String upper() under 30 μs** (currently 161 μs, 18x slower than Rust)
