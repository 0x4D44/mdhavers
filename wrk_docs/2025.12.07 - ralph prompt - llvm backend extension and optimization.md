# LLVM Backend Extension and Performance Optimization

## Goal
Extend the LLVM backend to support all language features and optimize generated code to reduce the performance gap with Rust (currently ~4-5x slower).

## Success Criteria
1. All standard library functions work in native compilation (`tae_string`, `tae_int`, `tae_float`, etc.)
2. All benchmarks in `benchmarks/mdhavers/` compile and run natively
3. Performance improved by at least 2x (target: within 2-3x of Rust)
4. No regressions in existing functionality
5. Native compilation of `fib(35)` completes in under 100ms (currently 166ms)

## Part 1: Missing Function Support

### Currently Missing Functions

Based on benchmark failures, these functions need LLVM implementation:

1. **Type Conversion Functions**
   - `tae_string(value)` - Convert any value to string
   - `tae_int(value)` - Convert to integer
   - `tae_float(value)` - Convert to float

2. **String Operations**
   - String concatenation with `+` operator (partially implemented)
   - String comparison operators

3. **List Operations** (verify these work)
   - `shove(list, item)` - Append to list
   - `len(list)` - Get length
   - List indexing `list[i]`
   - List concatenation `list1 + list2`

### Implementation Approach for tae_string

```rust
// In codegen.rs, add inline_tae_string function
fn inline_tae_string(&mut self, value: BasicValueEnum<'ctx>) -> Result<BasicValueEnum<'ctx>, HaversError> {
    let tag = self.extract_tag(value)?;
    let data = self.extract_data(value)?;

    // Create blocks for each type
    let current_fn = self.current_function.unwrap();
    let nil_block = self.context.append_basic_block(current_fn, "str_nil");
    let bool_block = self.context.append_basic_block(current_fn, "str_bool");
    let int_block = self.context.append_basic_block(current_fn, "str_int");
    let float_block = self.context.append_basic_block(current_fn, "str_float");
    let string_block = self.context.append_basic_block(current_fn, "str_string");
    let merge_block = self.context.append_basic_block(current_fn, "str_merge");

    // Switch on tag
    // For each type, format to string using snprintf
    // Return string value
}
```

### Required libc Functions

Ensure these are declared and used:
- `snprintf` - Format integers/floats to string
- `sprintf` - Alternative formatting
- `strlen` - String length
- `strcpy` - String copy
- `strcat` - String concatenation
- `malloc` - Memory allocation for strings

## Part 2: Performance Optimization

### Current Performance Profile

| Metric | Current | Target |
|--------|---------|--------|
| fib(35) native | 166ms | <100ms |
| vs Rust ratio | 4.5x | <2.5x |

### Optimization Strategies

#### 1. Type Specialization for Integers

Currently, every operation goes through the tagged union:
```
{i8 tag, i64 data}
```

For known-integer operations, generate direct i64 arithmetic:
```llvm
; Current (slow)
%left = call {i8, i64} @inline_add({i8, i64} %a, {i8, i64} %b)

; Optimized for known ints
%result = add i64 %a_data, %b_data
```

**Implementation:**
- Track inferred types during compilation
- Use `src/llvm/types.rs` InferredType enum
- Generate specialized code paths for int+int, float+float

#### 2. Inline Small Functions

For small recursive functions like fibonacci:
- Use LLVM's inline hints
- Add `alwaysinline` attribute to small functions
- Configure PassManager for aggressive inlining

```rust
// Add to function creation
function.add_attribute(AttributeLoc::Function,
    self.context.create_string_attribute("alwaysinline", ""));
```

#### 3. Enable LLVM Optimization Passes

Currently `run_optimization_passes` only verifies:
```rust
fn run_optimization_passes(&self, module: &Module) -> Result<(), HaversError> {
    if let Err(e) = module.verify() { ... }
    Ok(())
}
```

Add actual optimization passes:
```rust
use inkwell::passes::{PassManager, PassManagerBuilder};

fn run_optimization_passes(&self, module: &Module) -> Result<(), HaversError> {
    module.verify()?;

    let pass_manager_builder = PassManagerBuilder::create();
    pass_manager_builder.set_optimization_level(self.opt_level);

    let fpm = PassManager::create(module);
    pass_manager_builder.populate_function_pass_manager(&fpm);

    // Run on all functions
    fpm.initialize();
    for function in module.get_functions() {
        fpm.run_on(&function);
    }
    fpm.finalize();

    let mpm = PassManager::create(());
    pass_manager_builder.populate_module_pass_manager(&mpm);
    mpm.run_on(module);

    Ok(())
}
```

#### 4. Tail Call Optimization

For recursive functions, detect and optimize tail calls:
```rust
// When generating a return that's a function call
if is_tail_call {
    call_instruction.set_tail_call(true);
}
```

#### 5. Reduce Tag Checking Overhead

For operations where types are statically known:
- Skip runtime tag checks
- Generate direct operations

Example - when both operands are literals:
```
ken x = 5 + 3  # Both known to be ints at compile time
```

Generate:
```llvm
%x = add i64 5, 3  ; Direct add, no tag checks
```

#### 6. Use LLVM Intrinsics

Replace some operations with LLVM intrinsics:
- `llvm.expect` for branch prediction hints
- `llvm.assume` for type assumptions
- Math intrinsics for floor/ceil/etc.

### Files to Modify

1. **`src/llvm/codegen.rs`**
   - Add `inline_tae_string`, `inline_tae_int`, `inline_tae_float`
   - Add type specialization in arithmetic operations
   - Add tail call detection

2. **`src/llvm/compiler.rs`**
   - Implement proper optimization passes in `run_optimization_passes`
   - Add optimization level configuration

3. **`src/llvm/types.rs`**
   - Extend InferredType tracking
   - Add type inference during compilation

4. **`src/llvm/mod.rs`**
   - Ensure all modules are properly exported

### Testing Plan

1. **Correctness Tests**
   - Run all existing tests with native compilation
   - Verify benchmark outputs match interpreter

2. **Performance Tests**
   - Measure fib(35) before and after each optimization
   - Track improvements incrementally

3. **Regression Tests**
   - Ensure existing native features still work
   - Test edge cases

### Implementation Order

1. **Phase 1: Missing Functions** (Priority: High)
   - Implement `tae_string` for all types
   - Test with benchmark programs
   - Verify all benchmarks compile natively

2. **Phase 2: LLVM Optimization Passes** (Priority: High)
   - Add PassManager with optimization passes
   - Measure performance improvement
   - Target: 20-30% improvement

3. **Phase 3: Type Specialization** (Priority: Medium)
   - Add integer specialization for arithmetic
   - Add float specialization
   - Target: Additional 20-30% improvement

4. **Phase 4: Tail Call Optimization** (Priority: Medium)
   - Detect tail recursive calls
   - Add tail call attribute
   - Target: Significant improvement for recursive functions

5. **Phase 5: Fine-tuning** (Priority: Low)
   - Inline hints for small functions
   - Branch prediction hints
   - Final polish

### Metrics to Track

After each phase, record:
- `fib(35)` execution time
- `fib(40)` execution time
- Quicksort 500 elements time
- Binary size
- Compilation time

### Expected Results

| Phase | fib(35) Time | vs Rust |
|-------|--------------|---------|
| Current | 166ms | 4.5x |
| After Phase 2 | ~120ms | 3.2x |
| After Phase 3 | ~90ms | 2.4x |
| After Phase 4 | ~70ms | 1.9x |
| Target | <100ms | <2.5x |

## Notes

- Start with quick wins (optimization passes) before complex changes
- Measure after each change to track progress
- Keep backward compatibility with existing features
- The LLVM PassManager API may vary by inkwell version - check docs
- Consider using `cargo bench` for consistent measurements
